{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "_JnCWHu0DSE_"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "shopee_product_matching_path = kagglehub.competition_download('shopee-product-matching')\n",
        "nikitajz_faiss_163_path = kagglehub.dataset_download('nikitajz/faiss-163')\n",
        "aerdem4_sparse_dot_topn_029_path = kagglehub.dataset_download('aerdem4/sparse-dot-topn-029')\n",
        "lyakaap_timm045_path = kagglehub.dataset_download('lyakaap/timm045')\n",
        "lyakaap_editdistance_path = kagglehub.dataset_download('lyakaap/editdistance')\n",
        "lyakaap_bert_indo_path = kagglehub.dataset_download('lyakaap/bert-indo')\n",
        "tkm2261_shopee_libs_path = kagglehub.dataset_download('tkm2261/shopee-libs')\n",
        "cdeotte_rapids_path = kagglehub.dataset_download('cdeotte/rapids')\n",
        "lyakaap_bertmultilingual_path = kagglehub.dataset_download('lyakaap/bertmultilingual')\n",
        "lyakaap_bertxlm_path = kagglehub.dataset_download('lyakaap/bertxlm')\n",
        "lyakaap_shopee_path = kagglehub.dataset_download('lyakaap/shopee')\n",
        "tkm2261_shopee_cache_path = kagglehub.dataset_download('tkm2261/shopee-cache')\n",
        "tkm2261_shopee_metric_resnet50d512_0328_newfold_path = kagglehub.dataset_download('tkm2261/shopee-metric-resnet50d512-0328-newfold')\n",
        "lyakaap_shopee_meta_models_path = kagglehub.dataset_download('lyakaap/shopee-meta-models')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "8vwjYoLZDSFA"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install ../input/faiss-163/faiss_gpu-1.6.3-cp37-cp37m-manylinux2010_x86_64.whl\n",
        "!pip install ../input/shopee-libs/editdistance-0.5.3-cp37-cp37m-manylinux1_x86_64.whl"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "C9OOghxhDSFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lyk_config.py\n",
        "\n",
        "k = 50\n",
        "conf_th = 0.7\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "DEBUG = len(pd.read_csv('../input/shopee-product-matching/test.csv')) == 3\n",
        "\n",
        "def load_data():\n",
        "    if DEBUG:\n",
        "        nrows = 1000\n",
        "        df = pd.read_csv('../input/shopee-product-matching/train.csv', nrows=nrows, usecols=['posting_id', 'image', 'title'])\n",
        "#         nrows = None\n",
        "#         df = pd.read_csv('../input/shopee-product-matching/train.csv', nrows=nrows, usecols=['posting_id', 'image', 'title']).append(\n",
        "#              pd.read_csv('../input/shopee-product-matching/train.csv', nrows=nrows, usecols=['posting_id', 'image', 'title'])).reset_index(drop=True)\n",
        "        img_dir = Path('../input/shopee-product-matching/train_images/')\n",
        "    else:\n",
        "        nrows = None\n",
        "        df = pd.read_csv('../input/shopee-product-matching/test.csv', usecols=['posting_id', 'image', 'title'])\n",
        "        img_dir = Path('../input/shopee-product-matching/test_images/')\n",
        "    return df, img_dir"
      ],
      "metadata": {
        "trusted": true,
        "id": "v5ikpBswDSFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image similarity, Multi-modal similarity"
      ],
      "metadata": {
        "id": "DePWyGgsDSFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%python\n",
        "from lyk_config import k, conf_th, DEBUG, load_data\n",
        "\n",
        "import sys\n",
        "sys.path.append('../input/timm045/')\n",
        "import timm\n",
        "\n",
        "from itertools import zip_longest\n",
        "import json\n",
        "import math\n",
        "import gc\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms import Resize, RandomHorizontalFlip, ColorJitter, Normalize, Compose, RandomResizedCrop, CenterCrop, ToTensor\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import joblib\n",
        "from scipy.sparse import hstack, vstack, csc_matrix, csr_matrix\n",
        "import editdistance\n",
        "import networkx as nx\n",
        "from transformers import BertConfig, BertModel, BertTokenizerFast\n",
        "\n",
        "NUM_CLASSES = 11014\n",
        "NUM_WORKERS = 2\n",
        "SEED = 0\n",
        "\n",
        "\n",
        "def gem(x, p=3, eps=1e-6):\n",
        "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
        "\n",
        "\n",
        "class ShopeeNet(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 backbone,\n",
        "                 num_classes,\n",
        "                 fc_dim=512,\n",
        "                 s=30, margin=0.5, p=3):\n",
        "        super(ShopeeNet, self).__init__()\n",
        "\n",
        "        self.backbone = backbone\n",
        "        self.backbone.reset_classifier(num_classes=0)  # remove classifier\n",
        "\n",
        "        self.fc = nn.Linear(self.backbone.num_features, fc_dim)\n",
        "        self.bn = nn.BatchNorm1d(fc_dim)\n",
        "        self._init_params()\n",
        "        self.p = p\n",
        "\n",
        "    def _init_params(self):\n",
        "        nn.init.xavier_normal_(self.fc.weight)\n",
        "        nn.init.constant_(self.fc.bias, 0)\n",
        "        nn.init.constant_(self.bn.weight, 1)\n",
        "        nn.init.constant_(self.bn.bias, 0)\n",
        "\n",
        "    def extract_feat(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        x = self.backbone.forward_features(x)\n",
        "        if isinstance(x, tuple):\n",
        "            x = (x[0] + x[1]) / 2\n",
        "            x = self.bn(x)\n",
        "        else:\n",
        "            x = gem(x, p=self.p).view(batch_size, -1)\n",
        "            x = self.fc(x)\n",
        "            x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, label):\n",
        "        feat = self.extract_feat(x)\n",
        "        x = self.loss_module(feat, label)\n",
        "        return x, feat\n",
        "\n",
        "\n",
        "class ShopeeDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.df.iloc[index]\n",
        "        img = read_image(str(self.img_dir / row['image']))\n",
        "        _, h, w = img.shape\n",
        "        st_size = (self.img_dir / row['image']).stat().st_size\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, row['title'], h, w, st_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "\n",
        "class MultiModalNet(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 backbone,\n",
        "                 bert_model,\n",
        "                 num_classes,\n",
        "                 tokenizer,\n",
        "                 max_len=32,\n",
        "                 fc_dim=512,\n",
        "                 s=30, margin=0.5, p=3, loss='ArcMarginProduct'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = backbone\n",
        "        self.backbone.reset_classifier(num_classes=0)  # remove classifier\n",
        "\n",
        "        self.bert_model = bert_model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.fc = nn.Linear(self.bert_model.config.hidden_size + self.backbone.num_features, fc_dim)\n",
        "        self.bn = nn.BatchNorm1d(fc_dim)\n",
        "        self._init_params()\n",
        "        self.p = p\n",
        "\n",
        "    def _init_params(self):\n",
        "        nn.init.xavier_normal_(self.fc.weight)\n",
        "        nn.init.constant_(self.fc.bias, 0)\n",
        "        nn.init.constant_(self.bn.weight, 1)\n",
        "        nn.init.constant_(self.bn.bias, 0)\n",
        "\n",
        "    def extract_feat(self, img, title):\n",
        "        batch_size = img.shape[0]\n",
        "        img = self.backbone.forward_features(img)\n",
        "        img = gem(img, p=self.p).view(batch_size, -1)\n",
        "\n",
        "        tokenizer_output = self.tokenizer(title, truncation=True, padding=True, max_length=self.max_len)\n",
        "        input_ids = torch.LongTensor(tokenizer_output['input_ids']).to('cuda')\n",
        "        token_type_ids = torch.LongTensor(tokenizer_output['token_type_ids']).to('cuda')\n",
        "        attention_mask = torch.LongTensor(tokenizer_output['attention_mask']).to('cuda')\n",
        "        title = self.bert_model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
        "        # x = x.last_hidden_state.sum(dim=1) / attention_mask.sum(dim=1, keepdims=True)\n",
        "        title = title.last_hidden_state.mean(dim=1)\n",
        "\n",
        "        x = torch.cat([img, title], dim=1)\n",
        "        x = self.fc(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "####\n",
        "\n",
        "df, img_dir = load_data()\n",
        "\n",
        "###\n",
        "\n",
        "checkpoint1 = torch.load('../input/shopee/v45.pth')\n",
        "checkpoint2 = torch.load('../input/shopee/v34.pth')\n",
        "checkpoint3 = torch.load('../input/shopee/v79.pth')\n",
        "params1 = checkpoint1['params']\n",
        "params2 = checkpoint2['params']\n",
        "params3 = checkpoint3['params']\n",
        "\n",
        "transform = Compose([\n",
        "    Resize(size=params1['test_size'] + 32, interpolation=Image.BICUBIC),\n",
        "    CenterCrop((params1['test_size'], params1['test_size'])),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "dataset = ShopeeDataset(df=df, img_dir=img_dir, transform=None)\n",
        "data_loader = DataLoader(dataset, batch_size=8, shuffle=False,\n",
        "                         drop_last=False, pin_memory=True, num_workers=NUM_WORKERS, collate_fn=lambda x: x)\n",
        "\n",
        "backbone = timm.create_model(model_name=params1['backbone'], pretrained=False)\n",
        "model1 = ShopeeNet(backbone, num_classes=0, fc_dim=params1['fc_dim'])\n",
        "model1 = model1.to('cuda')\n",
        "model1.load_state_dict(checkpoint1['model'], strict=False)\n",
        "model1.train(False)\n",
        "model1.p = params1['p_eval']\n",
        "\n",
        "backbone = timm.create_model(model_name=params2['backbone'], pretrained=False)\n",
        "model2 = ShopeeNet(backbone, num_classes=0, fc_dim=params2['fc_dim'])\n",
        "model2 = model2.to('cuda')\n",
        "model2.load_state_dict(checkpoint2['model'], strict=False)\n",
        "model2.train(False)\n",
        "model2.p = params2['p_eval']\n",
        "\n",
        "backbone = timm.create_model(model_name=params3['backbone'], pretrained=False)\n",
        "tokenizer = BertTokenizerFast(vocab_file='../input/bert-indo/vocab.txt')\n",
        "bert_config = BertConfig.from_json_file('../input/bert-indo/config.json')\n",
        "bert_model = BertModel(bert_config)\n",
        "model3 = MultiModalNet(backbone, bert_model, num_classes=0, tokenizer=tokenizer, max_len=params3['max_len'],\n",
        "                       fc_dim=params3['fc_dim'], s=params3['s'], margin=params3['margin'], loss=params3['loss'])\n",
        "model3 = model3.to('cuda')\n",
        "model3.load_state_dict(checkpoint3['model'], strict=False)\n",
        "model3.train(False)\n",
        "model3.p = params3['p_eval']\n",
        "\n",
        "img_feats1 = []\n",
        "img_feats2 = []\n",
        "mm_feats = []\n",
        "img_hs = []\n",
        "img_ws = []\n",
        "st_sizes = []\n",
        "for batch in tqdm(data_loader, total=len(data_loader), miniters=None, ncols=55):\n",
        "    img, title, h, w, st_size = list(zip(*batch))\n",
        "    img = torch.cat([transform(x.to('cuda').float() / 255)[None] for x in img], axis=0)\n",
        "    title = list(title)\n",
        "    with torch.no_grad():\n",
        "        feats_minibatch1 = model1.extract_feat(img)\n",
        "        img_feats1.append(feats_minibatch1.cpu().numpy())\n",
        "        feats_minibatch2 = model2.extract_feat(img)\n",
        "        img_feats2.append(feats_minibatch2.cpu().numpy())\n",
        "        feats_minibatch3 = model3.extract_feat(img, title)\n",
        "        mm_feats.append(feats_minibatch3.cpu().numpy())\n",
        "    img_hs.extend(list(h))\n",
        "    img_ws.extend(list(w))\n",
        "    st_sizes.extend(list(st_size))\n",
        "\n",
        "img_feats1 = np.concatenate(img_feats1)\n",
        "img_feats1 /= np.linalg.norm(img_feats1, 2, axis=1, keepdims=True)\n",
        "img_feats2 = np.concatenate(img_feats2)\n",
        "img_feats2 /= np.linalg.norm(img_feats2, 2, axis=1, keepdims=True)\n",
        "mm_feats = np.concatenate(mm_feats)\n",
        "mm_feats /= np.linalg.norm(mm_feats, 2, axis=1, keepdims=True)\n",
        "\n",
        "np.save('/tmp/img_feats1', img_feats1)\n",
        "np.save('/tmp/img_feats2', img_feats2)\n",
        "\n",
        "img_feats = np.concatenate([\n",
        "    img_feats1 * 1.0,\n",
        "    img_feats2 * 1.0,\n",
        "], axis=1)\n",
        "img_feats /= np.linalg.norm(img_feats, 2, axis=1, keepdims=True)\n",
        "###\n",
        "\n",
        "np.save('/tmp/img_feats', img_feats)\n",
        "\n",
        "res = faiss.StandardGpuResources()\n",
        "index_img = faiss.IndexFlatIP(params1['fc_dim'] + params2['fc_dim'])\n",
        "index_img = faiss.index_cpu_to_gpu(res, 0, index_img)\n",
        "index_img.add(img_feats)\n",
        "similarities_img, indexes_img = index_img.search(img_feats, k)\n",
        "\n",
        "\n",
        "joblib.dump([similarities_img, indexes_img], '/tmp/lyk_img_data.pkl')\n",
        "joblib.dump([st_sizes, img_hs, img_ws], '/tmp/lyk_img_meta_data.pkl')\n",
        "\n",
        "res = faiss.StandardGpuResources()\n",
        "index_mm = faiss.IndexFlatIP(params3['fc_dim'])\n",
        "index_mm = faiss.index_cpu_to_gpu(res, 0, index_mm)\n",
        "index_mm.add(mm_feats)\n",
        "similarities_mm, indexes_mm = index_mm.search(mm_feats, k)\n",
        "\n",
        "joblib.dump([similarities_mm, indexes_mm], '/tmp/lyk_mm_data.pkl')\n",
        "\n",
        "### for TKM\n",
        "np.save('/tmp/mm_feats', mm_feats)"
      ],
      "metadata": {
        "trusted": true,
        "id": "mkxdH6DwDSFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### image QE"
      ],
      "metadata": {
        "id": "grzmM55WDSFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%python\n",
        "import gc\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "def query_expansion(feats, sims, topk_idx, alpha=0.5, k=2):\n",
        "    weights = np.expand_dims(sims[:, :k] ** alpha, axis=-1).astype(np.float32)\n",
        "    feats = (feats[topk_idx[:, :k]] * weights).sum(axis=1)\n",
        "    return feats\n",
        "\n",
        "img_feats = np.load('/tmp/img_feats.npy')\n",
        "\n",
        "res = faiss.StandardGpuResources()\n",
        "index_img = faiss.IndexFlatIP(img_feats.shape[1])\n",
        "index_img = faiss.index_cpu_to_gpu(res, 0, index_img)\n",
        "index_img.add(img_feats)\n",
        "img_D, img_I = index_img.search(img_feats, 60)\n",
        "\n",
        "np.save('/tmp/img_D', img_D)\n",
        "np.save('/tmp/img_I', img_I)\n",
        "\n",
        "img_feats_qe = query_expansion(img_feats, img_D, img_I)\n",
        "img_feats_qe /= np.linalg.norm(img_feats_qe, 2, axis=1, keepdims=True)\n",
        "\n",
        "img_feats = np.hstack([img_feats, img_feats_qe])\n",
        "img_feats /= np.linalg.norm(img_feats, axis=1).reshape((-1, 1))\n",
        "\n",
        "index = faiss.IndexFlatIP(img_feats.shape[1])\n",
        "res = faiss.StandardGpuResources()\n",
        "index = faiss.index_cpu_to_gpu(res, 0, index)\n",
        "\n",
        "index.add(img_feats)\n",
        "img_D, img_I = index.search(img_feats, 60)\n",
        "\n",
        "np.save('/tmp/img_D_qe', img_D)\n",
        "np.save('/tmp/img_I_qe', img_I)\n",
        "\n",
        "print('end')"
      ],
      "metadata": {
        "trusted": true,
        "id": "YvKaGqFaDSFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-modal QE"
      ],
      "metadata": {
        "id": "dE4e5TiYDSFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%python\n",
        "import gc\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "def query_expansion(feats, sims, topk_idx, alpha=0.5, k=2):\n",
        "    weights = np.expand_dims(sims[:, :k] ** alpha, axis=-1).astype(np.float32)\n",
        "    feats = (feats[topk_idx[:, :k]] * weights).sum(axis=1)\n",
        "    return feats\n",
        "\n",
        "mm_feats = np.load('/tmp/mm_feats.npy')\n",
        "\n",
        "res = faiss.StandardGpuResources()\n",
        "index_mm = faiss.IndexFlatIP(mm_feats.shape[1])\n",
        "index_mm = faiss.index_cpu_to_gpu(res, 0, index_mm)\n",
        "index_mm.add(mm_feats)\n",
        "mm_D, mm_I = index_mm.search(mm_feats, 60)\n",
        "\n",
        "np.save('/tmp/mut_D', mm_D)\n",
        "np.save('/tmp/mut_I', mm_I)\n",
        "\n",
        "mm_feats_qe = query_expansion(mm_feats, mm_D, mm_I)\n",
        "mm_feats_qe /= np.linalg.norm(mm_feats_qe, 2, axis=1, keepdims=True)\n",
        "\n",
        "mm_feats = np.hstack([mm_feats, mm_feats_qe])\n",
        "mm_feats /= np.linalg.norm(mm_feats, axis=1).reshape((-1, 1))\n",
        "\n",
        "index = faiss.IndexFlatIP(mm_feats.shape[1])\n",
        "res = faiss.StandardGpuResources()\n",
        "index = faiss.index_cpu_to_gpu(res, 0, index)\n",
        "\n",
        "index.add(mm_feats)\n",
        "mm_D, mm_I = index.search(mm_feats, 60)\n",
        "\n",
        "np.save('/tmp/mut_D_qe', mm_D)\n",
        "np.save('/tmp/mut_I_qe', mm_I)"
      ],
      "metadata": {
        "trusted": true,
        "id": "YVv2iHSQDSFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT similarity"
      ],
      "metadata": {
        "id": "wwG9uwY4DSFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%python\n",
        "from lyk_config import k, conf_th, DEBUG, load_data\n",
        "import sys\n",
        "sys.path.append('../input/timm045/')\n",
        "import timm\n",
        "\n",
        "from itertools import zip_longest\n",
        "import json\n",
        "import math\n",
        "import gc\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms import Resize, RandomHorizontalFlip, ColorJitter, Normalize, Compose, RandomResizedCrop, CenterCrop, ToTensor\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import joblib\n",
        "from scipy.sparse import hstack, vstack, csc_matrix, csr_matrix\n",
        "import editdistance\n",
        "import networkx as nx\n",
        "\n",
        "from transformers import BertConfig, BertModel, BertTokenizerFast\n",
        "\n",
        "NUM_CLASSES = 11014\n",
        "NUM_WORKERS = 2\n",
        "SEED = 0\n",
        "\n",
        "\n",
        "def gem(x, p=3, eps=1e-6):\n",
        "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
        "\n",
        "\n",
        "class BertNet(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 bert_model,\n",
        "                 num_classes,\n",
        "                 tokenizer,\n",
        "                 max_len=32,\n",
        "                 fc_dim=512,\n",
        "                 simple_mean=True,\n",
        "                 s=30, margin=0.5, p=3, loss='ArcMarginProduct'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert_model = bert_model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.fc = nn.Linear(self.bert_model.config.hidden_size, fc_dim)\n",
        "        self.bn = nn.BatchNorm1d(fc_dim)\n",
        "        self._init_params()\n",
        "        self.p = p\n",
        "        self.simple_mean = simple_mean\n",
        "\n",
        "    def _init_params(self):\n",
        "        nn.init.xavier_normal_(self.fc.weight)\n",
        "        nn.init.constant_(self.fc.bias, 0)\n",
        "        nn.init.constant_(self.bn.weight, 1)\n",
        "        nn.init.constant_(self.bn.bias, 0)\n",
        "\n",
        "    def extract_feat(self, x):\n",
        "        tokenizer_output = self.tokenizer(x, truncation=True, padding=True, max_length=self.max_len)\n",
        "        if 'token_type_ids' in tokenizer_output:\n",
        "            input_ids = torch.LongTensor(tokenizer_output['input_ids']).to('cuda')\n",
        "            token_type_ids = torch.LongTensor(tokenizer_output['token_type_ids']).to('cuda')\n",
        "            attention_mask = torch.LongTensor(tokenizer_output['attention_mask']).to('cuda')\n",
        "            x = self.bert_model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
        "        else:\n",
        "            input_ids = torch.LongTensor(tokenizer_output['input_ids']).to('cuda')\n",
        "            attention_mask = torch.LongTensor(tokenizer_output['attention_mask']).to('cuda')\n",
        "            x = self.bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        if self.simple_mean:\n",
        "            x = x.last_hidden_state.mean(dim=1)\n",
        "        else:\n",
        "            x = torch.sum(x.last_hidden_state * attention_mask.unsqueeze(-1), dim=1) / attention_mask.sum(dim=1, keepdims=True)\n",
        "        x = self.fc(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class BertDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.df.iloc[index]\n",
        "\n",
        "        if 'y' in row.keys():\n",
        "            target = torch.tensor(row['y'], dtype=torch.long)\n",
        "            return row['title'], target\n",
        "        else:\n",
        "            return row['title']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "df, img_dir = load_data()\n",
        "\n",
        "checkpoint = torch.load('../input/shopee/v75.pth')\n",
        "checkpoint2 = torch.load('../input/shopee/v102.pth')\n",
        "checkpoint3 = torch.load('../input/shopee/v103.pth')\n",
        "\n",
        "params_bert = checkpoint['params']\n",
        "params_bert2 = checkpoint2['params']\n",
        "params_bert3 = checkpoint3['params']\n",
        "\n",
        "datasets = {\n",
        "    'valid': BertDataset(df=df)\n",
        "}\n",
        "data_loaders = {\n",
        "    'valid': DataLoader(datasets['valid'], batch_size=params_bert['batch_size'] * 2, shuffle=False,\n",
        "                        drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
        "}\n",
        "\n",
        "tokenizer = BertTokenizerFast(vocab_file='../input/bert-indo/vocab.txt')\n",
        "bert_config = BertConfig.from_json_file('../input/bert-indo/config.json')\n",
        "bert_model = BertModel(bert_config)\n",
        "model = BertNet(bert_model, num_classes=0, tokenizer=tokenizer, max_len=params_bert['max_len'], simple_mean=True,\n",
        "                fc_dim=params_bert['fc_dim'], s=params_bert['s'], margin=params_bert['margin'], loss=params_bert['loss'])\n",
        "\n",
        "model = model.to('cuda')\n",
        "model.load_state_dict(checkpoint['model'], strict=False)\n",
        "model.train(False)\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "\n",
        "model_name = params_bert2['model_name']\n",
        "tokenizer = AutoTokenizer.from_pretrained('../input/bertmultilingual/')\n",
        "bert_config = AutoConfig.from_pretrained('../input/bertmultilingual/')\n",
        "bert_model = AutoModel.from_config(bert_config)\n",
        "model2 = BertNet(bert_model, num_classes=0, tokenizer=tokenizer, max_len=params_bert['max_len'], simple_mean=False,\n",
        "                 fc_dim=params_bert['fc_dim'], s=params_bert['s'], margin=params_bert['margin'], loss=params_bert['loss'])\n",
        "model2 = model2.to('cuda')\n",
        "model2.load_state_dict(checkpoint2['model'], strict=False)\n",
        "model2.train(False)\n",
        "\n",
        "#########\n",
        "\n",
        "model_name = params_bert3['model_name']\n",
        "tokenizer = AutoTokenizer.from_pretrained('../input/bertxlm/')\n",
        "bert_config = AutoConfig.from_pretrained('../input/bertxlm/')\n",
        "bert_model = AutoModel.from_config(bert_config)\n",
        "model3 = BertNet(bert_model, num_classes=0, tokenizer=tokenizer, max_len=params_bert3['max_len'], simple_mean=False,\n",
        "                 fc_dim=params_bert3['fc_dim'], s=params_bert3['s'], margin=params_bert3['margin'], loss=params_bert3['loss'])\n",
        "model3 = model3.to('cuda')\n",
        "model3.load_state_dict(checkpoint3['model'], strict=False)\n",
        "model3.train(False)\n",
        "\n",
        "bert_feats1 = []\n",
        "bert_feats2 = []\n",
        "bert_feats3 = []\n",
        "for i, title in tqdm(enumerate(data_loaders['valid']),\n",
        "                     total=len(data_loaders['valid']), miniters=None, ncols=55):\n",
        "    with torch.no_grad():\n",
        "        bert_feats_minibatch = model.extract_feat(title)\n",
        "        bert_feats1.append(bert_feats_minibatch.cpu().numpy())\n",
        "        bert_feats_minibatch = model2.extract_feat(title)\n",
        "        bert_feats2.append(bert_feats_minibatch.cpu().numpy())\n",
        "        bert_feats_minibatch = model3.extract_feat(title)\n",
        "        bert_feats3.append(bert_feats_minibatch.cpu().numpy())\n",
        "\n",
        "bert_feats1 = np.concatenate(bert_feats1)\n",
        "bert_feats1 /= np.linalg.norm(bert_feats1, 2, axis=1, keepdims=True)\n",
        "bert_feats2 = np.concatenate(bert_feats2)\n",
        "bert_feats2 /= np.linalg.norm(bert_feats2, 2, axis=1, keepdims=True)\n",
        "bert_feats3 = np.concatenate(bert_feats3)\n",
        "bert_feats3 /= np.linalg.norm(bert_feats3, 2, axis=1, keepdims=True)\n",
        "\n",
        "bert_feats = np.concatenate([bert_feats1, bert_feats2], axis=1)\n",
        "bert_feats /= np.linalg.norm(bert_feats, 2, axis=1, keepdims=True)\n",
        "\n",
        "res = faiss.StandardGpuResources()\n",
        "index_bert = faiss.IndexFlatIP(params_bert['fc_dim'])\n",
        "index_bert = faiss.index_cpu_to_gpu(res, 0, index_bert)\n",
        "index_bert.add(bert_feats1)\n",
        "similarities_bert, indexes_bert = index_bert.search(bert_feats1, k)\n",
        "\n",
        "np.save('/tmp/bert_feats1', bert_feats1)\n",
        "np.save('/tmp/bert_feats2', bert_feats2)\n",
        "np.save('/tmp/bert_feats3', bert_feats3)\n",
        "\n",
        "bert_feats = np.concatenate([bert_feats1, bert_feats2, bert_feats3], axis=1)\n",
        "bert_feats /= np.linalg.norm(bert_feats, 2, axis=1, keepdims=True)\n",
        "\n",
        "np.save('/tmp/bert_feats', bert_feats)\n",
        "\n",
        "joblib.dump([similarities_bert, indexes_bert], '/tmp/lyk_bert_data.pkl')"
      ],
      "metadata": {
        "trusted": true,
        "id": "GdrEi4BUDSFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bert QE"
      ],
      "metadata": {
        "id": "PofB1tUIDSFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%python\n",
        "import gc\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "def query_expansion(feats, sims, topk_idx, alpha=0.5, k=2):\n",
        "    weights = np.expand_dims(sims[:, :k] ** alpha, axis=-1).astype(np.float32)\n",
        "    feats = (feats[topk_idx[:, :k]] * weights).sum(axis=1)\n",
        "    return feats\n",
        "\n",
        "brt_feats = np.load('/tmp/bert_feats.npy')\n",
        "\n",
        "res = faiss.StandardGpuResources()\n",
        "index_brt = faiss.IndexFlatIP(brt_feats.shape[1])\n",
        "index_brt = faiss.index_cpu_to_gpu(res, 0, index_brt)\n",
        "index_brt.add(brt_feats)\n",
        "brt_D, brt_I = index_brt.search(brt_feats, 60)\n",
        "\n",
        "np.save('/tmp/brt_D', brt_D)\n",
        "np.save('/tmp/brt_I', brt_I)\n",
        "\n",
        "del index_brt\n",
        "gc.collect()\n",
        "\n",
        "brt_feats_qe = query_expansion(brt_feats, brt_D, brt_I)\n",
        "brt_feats_qe /= np.linalg.norm(brt_feats_qe, 2, axis=1, keepdims=True)\n",
        "\n",
        "brt_feats = np.hstack([brt_feats, brt_feats_qe])\n",
        "brt_feats /= np.linalg.norm(brt_feats, axis=1).reshape((-1, 1))\n",
        "\n",
        "index = faiss.IndexFlatIP(brt_feats.shape[1])\n",
        "res = faiss.StandardGpuResources()\n",
        "index = faiss.index_cpu_to_gpu(res, 0, index)\n",
        "\n",
        "index.add(brt_feats)\n",
        "brt_D, brt_I = index.search(brt_feats, 60)\n",
        "\n",
        "np.save('/tmp/brt_D_qe', brt_D)\n",
        "np.save('/tmp/brt_I_qe', brt_I)\n",
        "print('end')"
      ],
      "metadata": {
        "trusted": true,
        "id": "warU6nrgDSFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image & BERT similarity"
      ],
      "metadata": {
        "id": "NNQTqwefDSFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%python\n",
        "import gc\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "def query_expansion(feats, sims, topk_idx, alpha=0.5, k=2):\n",
        "    weights = np.expand_dims(sims[:, :k] ** alpha, axis=-1).astype(np.float32)\n",
        "    feats = (feats[topk_idx[:, :k]] * weights).sum(axis=1)\n",
        "    return feats\n",
        "\n",
        "\n",
        "feats_bert = np.load('/tmp/bert_feats.npy')\n",
        "feats_img = np.load('/tmp/img_feats.npy')\n",
        "\n",
        "bth_feats = np.hstack([feats_bert, feats_img])\n",
        "bth_feats /= np.linalg.norm(bth_feats, 2, axis=1, keepdims=True)\n",
        "\n",
        "print(bth_feats.shape)\n",
        "\n",
        "res = faiss.StandardGpuResources()\n",
        "index = faiss.IndexFlatIP(bth_feats.shape[1])\n",
        "index = faiss.index_cpu_to_gpu(res, 0, index)\n",
        "index.add(bth_feats)\n",
        "\n",
        "bth_D, bth_I = index.search(bth_feats, 60)\n",
        "np.save('/tmp/bth_D', bth_D)\n",
        "np.save('/tmp/bth_I', bth_I)\n",
        "\n",
        "del index\n",
        "gc.collect()\n",
        "\n",
        "bth_feats_qe = query_expansion(bth_feats, bth_D, bth_I)\n",
        "bth_feats_qe /= np.linalg.norm(bth_feats_qe, 2, axis=1, keepdims=True)\n",
        "\n",
        "bth_feats = np.hstack([bth_feats, bth_feats_qe])\n",
        "bth_feats /= np.linalg.norm(bth_feats, axis=1).reshape((-1, 1))\n",
        "\n",
        "index = faiss.IndexFlatIP(bth_feats.shape[1])\n",
        "res = faiss.StandardGpuResources()\n",
        "index = faiss.index_cpu_to_gpu(res, 0, index)\n",
        "\n",
        "index.add(bth_feats)\n",
        "bth_D, bth_I = index.search(bth_feats, 60)\n",
        "\n",
        "np.save('/tmp/bth_D_qe', bth_D)\n",
        "np.save('/tmp/bth_I_qe', bth_I)\n",
        "print('end')"
      ],
      "metadata": {
        "trusted": true,
        "id": "MXF1VGN6DSFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lyakaap Side (GCN)"
      ],
      "metadata": {
        "id": "Wt4_-cqpDSFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%python\n",
        "from lyk_config import k, conf_th, DEBUG, load_data\n",
        "import sys\n",
        "sys.path.append('../input/timm045/')\n",
        "import timm\n",
        "\n",
        "from itertools import zip_longest\n",
        "import json\n",
        "import math\n",
        "import gc\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import joblib\n",
        "import lightgbm as lgb\n",
        "from scipy.sparse import hstack, vstack, csc_matrix, csr_matrix\n",
        "import editdistance\n",
        "import networkx as nx\n",
        "\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "NUM_CLASSES = 11014\n",
        "NUM_WORKERS = 2\n",
        "SEED = 0\n",
        "\n",
        "class GraphDataset(Dataset):\n",
        "\n",
        "    def __init__(self, feats=None, labels=None, weights=None, pair_tuples=None, k=50, top_neighbors=None):\n",
        "        self.feats = feats\n",
        "        self.labels = labels\n",
        "        self.weights = weights\n",
        "        self.pair_tuples = pair_tuples\n",
        "        self.k = k\n",
        "        self.top_neighbors = top_neighbors\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        i, j = self.pair_tuples[index]\n",
        "        feat = torch.FloatTensor(self.feats[i][j])\n",
        "\n",
        "        padding_i = [[0] * feat.shape[0]] * (self.k - len(self.top_neighbors[i]))\n",
        "        neighbor_feats_i = torch.FloatTensor([\n",
        "            self.feats[i][neighbor]\n",
        "            for neighbor in self.top_neighbors[i]\n",
        "        ] + padding_i)\n",
        "        padding_j = [[0] * feat.shape[0]] * (self.k - len(self.top_neighbors[j]))\n",
        "        neighbor_feats_j = torch.FloatTensor([\n",
        "            self.feats[j][neighbor]\n",
        "            for neighbor in self.top_neighbors[j]\n",
        "        ] + padding_j)\n",
        "        neighbor_feats = torch.cat([feat.unsqueeze(0), neighbor_feats_i, neighbor_feats_j], dim=0)\n",
        "\n",
        "        outputs = (feat, neighbor_feats)\n",
        "        if self.labels is not None:\n",
        "            outputs += (self.labels[i] == self.labels[j],)\n",
        "        if self.weights is not None:\n",
        "            outputs += (self.weights[i],)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pair_tuples)\n",
        "\n",
        "\n",
        "class GraphAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features, out_features, dropout=0.6, alpha=0.2, concat=True):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.alpha = alpha\n",
        "        self.concat = concat\n",
        "\n",
        "        self.W = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
        "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
        "        self.a = nn.Parameter(torch.empty(size=(2 * out_features, 1)))\n",
        "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
        "\n",
        "    def forward(self, h):\n",
        "        Wh = h @ self.W  # h.shape: (B, N, in_features), Wh.shape: (B, N, out_features)\n",
        "        a_input = self._prepare_attentional_mechanism_input(Wh)\n",
        "        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(3))\n",
        "\n",
        "        attention = F.softmax(e, dim=1)\n",
        "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
        "        h_prime = torch.bmm(attention, Wh)\n",
        "\n",
        "        if self.concat:\n",
        "            return F.elu(h_prime)\n",
        "        else:\n",
        "            return h_prime\n",
        "\n",
        "    def _prepare_attentional_mechanism_input(self, Wh):\n",
        "        B, N, D = Wh.shape\n",
        "\n",
        "        Wh_repeated_in_chunks = Wh.repeat_interleave(N, dim=1)\n",
        "        Wh_repeated_alternating = Wh.repeat(1, N, 1)\n",
        "\n",
        "        all_combinations_matrix = torch.cat([Wh_repeated_in_chunks, Wh_repeated_alternating], dim=2)\n",
        "        return all_combinations_matrix.view(-1, N, N, 2 * D)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n",
        "\n",
        "\n",
        "class GATPairClassifier(nn.Module):\n",
        "    def __init__(self, nfeat, nhid=8, nclass=1, dropout=0.6, alpha=0.2, nheads=8, pooling='first'):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.attentions = [GraphAttentionLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=True) for _ in range(nheads)]\n",
        "        for i, attention in enumerate(self.attentions):\n",
        "            self.add_module('attention_{}'.format(i), attention)\n",
        "\n",
        "        self.out_att = GraphAttentionLayer(nhid * nheads, nhid, dropout=dropout, alpha=alpha, concat=False)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(nfeat + nhid, nhid),\n",
        "            nn.PReLU(),\n",
        "            nn.BatchNorm1d(nhid),\n",
        "            nn.Linear(nhid, nclass),\n",
        "        )\n",
        "\n",
        "    def forward_gat(self, x):\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = torch.cat([att(x) for att in self.attentions], dim=2)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.elu(self.out_att(x))\n",
        "        if self.pooling == 'first':\n",
        "            return x[:, 0]\n",
        "        elif self.pooling == 'mean':\n",
        "            return x.mean(dim=1)\n",
        "\n",
        "    def forward(self, feats, neighbor_feats):\n",
        "        gat_feats = self.forward_gat(neighbor_feats)\n",
        "        cat_feats = torch.cat([feats, gat_feats], dim=1)\n",
        "        return self.classifier(cat_feats).squeeze(1)\n",
        "\n",
        "\n",
        "import time\n",
        "from contextlib import contextmanager\n",
        "from collections import defaultdict\n",
        "map_used_time = defaultdict(float)\n",
        "@contextmanager\n",
        "def timer(title):\n",
        "    t0 = time.time()\n",
        "    yield\n",
        "    tt = time.time() - t0\n",
        "    map_used_time[title] += tt\n",
        "    print(\"  {} - done in {:.5f}s\".format(title, tt))\n",
        "\n",
        "\n",
        "df, img_dir = load_data()\n",
        "\n",
        "stop_words = set([\n",
        "    'promo','diskon','baik','terbaik', 'murah',\n",
        "    'termurah', 'harga', 'price', 'best', 'seller',\n",
        "    'bestseller', 'ready', 'stock', 'stok', 'limited',\n",
        "    'bagus', 'kualitas', 'berkualitas', 'hari', 'ini',\n",
        "    'jadi', 'gratis',\n",
        "])\n",
        "\n",
        "\n",
        "titles = [\n",
        "    title.translate(str.maketrans({_: ' ' for _ in string.punctuation}))\n",
        "    for title in df['title'].str.lower().values\n",
        "]\n",
        "\n",
        "tokenizer = TweetTokenizer()\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words,\n",
        "                                   binary=True,\n",
        "                                   min_df=2,\n",
        "                                   token_pattern='(?u)\\\\b\\\\w+\\\\b',\n",
        "                                   tokenizer=tokenizer.tokenize,\n",
        "                                   dtype=np.float32,\n",
        "                                   norm='l2')\n",
        "tfidf_feats = tfidf_vectorizer.fit_transform(titles)\n",
        "simmat_tfidf = tfidf_feats @ tfidf_feats.T\n",
        "\n",
        "with timer('load'):\n",
        "    st_sizes, img_hs, img_ws = joblib.load('/tmp/lyk_img_meta_data.pkl')\n",
        "    similarities_img = np.load('/tmp/img_D_qe.npy')[:, :k]\n",
        "    indexes_img = np.load('/tmp/img_I_qe.npy')[:, :k]\n",
        "\n",
        "    similarities_bert = np.load('/tmp/brt_D_qe.npy')[:, :k]\n",
        "    indexes_bert = np.load('/tmp/brt_I_qe.npy')[:, :k]\n",
        "\n",
        "    similarities_mm = np.load('/tmp/mut_D_qe.npy')[:, :k]\n",
        "    indexes_mm = np.load('/tmp/mut_I_qe.npy')[:, :k]\n",
        "\n",
        "    row = indexes_bert.ravel()\n",
        "    col = np.arange(len(indexes_bert)).repeat(k)\n",
        "    data = similarities_bert.ravel()\n",
        "    simmat_bert = {(i, j): d for i, j, d in zip(col, row, data)}\n",
        "\n",
        "    row = indexes_img.ravel()\n",
        "    col = np.arange(len(indexes_img)).repeat(k)\n",
        "    data = similarities_img.ravel()\n",
        "    simmat_img = {(i, j): d for i, j, d in zip(col, row, data)}\n",
        "\n",
        "    row = indexes_mm.ravel()\n",
        "    col = np.arange(len(indexes_mm)).repeat(k)\n",
        "    data = similarities_mm.ravel()\n",
        "    simmat_mm = {(i, j): d for i, j, d in zip(col, row, data)}\n",
        "\n",
        "del row, col, data\n",
        "gc.collect()\n",
        "\n",
        "ckpt = torch.load('../input/shopee-meta-models/v135.pth')\n",
        "params = ckpt['params']\n",
        "\n",
        "top_neighbors = defaultdict(list)\n",
        "feats = defaultdict(lambda: defaultdict())\n",
        "\n",
        "pair_tuples = []\n",
        "for i in tqdm(range(len(df))):\n",
        "    right_indexes = set(indexes_img[i, :k].tolist() + indexes_bert[i, :k].tolist())\n",
        "    right_indexes.remove(i)  # remove self\n",
        "\n",
        "    right_indexes = list(right_indexes)\n",
        "    scores = {}\n",
        "    for j in right_indexes:\n",
        "        pair_tuples.append((i, j))\n",
        "\n",
        "        sim_img = simmat_img.get((i, j), 0)\n",
        "        sim_bert = simmat_bert.get((i, j), 0)\n",
        "        sim_mm = simmat_mm.get((i, j), 0)\n",
        "        sim_tfidf = simmat_tfidf[i, j]\n",
        "        if sim_img == 0 and sim_bert == 0:\n",
        "            continue\n",
        "\n",
        "        feats[i][j] = [\n",
        "            sim_img,\n",
        "            sim_tfidf,\n",
        "            sim_bert,\n",
        "            sim_mm,\n",
        "        ]\n",
        "        scores[j] = sim_img + sim_tfidf + sim_bert + sim_mm\n",
        "\n",
        "    top_neighbors[i] = sorted(right_indexes, key=lambda x: scores[x], reverse=True)[:params['k']]\n",
        "\n",
        "dataset = GraphDataset(\n",
        "    feats=feats,\n",
        "    pair_tuples=pair_tuples,\n",
        "    k=params['k'],\n",
        "    top_neighbors=top_neighbors,\n",
        ")\n",
        "loader = DataLoader(dataset, batch_size=2 ** 12, shuffle=False, drop_last=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "gat = GATPairClassifier(nfeat=len(feats[i][j]), nhid=params['nhid'],\n",
        "                        dropout=params['dropout'], nheads=params['nheads'], pooling=params['pooling'])\n",
        "gat.to('cuda').eval()\n",
        "gat.load_state_dict(ckpt['model'])\n",
        "\n",
        "del tfidf_feats\n",
        "gc.collect()\n",
        "###\n",
        "\n",
        "preds = []\n",
        "for feats, neighbor_feats in tqdm(loader, desc='predict', leave=False):\n",
        "    feats = feats.to('cuda', non_blocking=True)\n",
        "    neighbor_feats = neighbor_feats.to('cuda', non_blocking=True)\n",
        "    with torch.no_grad():\n",
        "        pred = gat(feats, neighbor_feats).sigmoid().detach().cpu().numpy().tolist()\n",
        "        preds.extend(pred)\n",
        "\n",
        "conf_th_gcn = 0.3\n",
        "df_pair = pd.DataFrame()\n",
        "col, row = list(zip(*pair_tuples))\n",
        "df_pair['i'] = col\n",
        "df_pair['j'] = row\n",
        "\n",
        "df_pair['posting_id'] = df['posting_id'].values[df_pair['i'].values]\n",
        "df_pair['posting_id_target'] = df['posting_id'].values[df_pair['j'].values]\n",
        "\n",
        "df_pair = df_pair[['posting_id', 'posting_id_target']]\n",
        "df_pair['pred'] = preds\n",
        "df_pair['pred'] -= conf_th_gcn\n",
        "\n",
        "df_pair.to_pickle('submission_lyak_gcn.pkl')\n",
        "df_pair"
      ],
      "metadata": {
        "trusted": true,
        "id": "x2j3gYDeDSFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lyakaap Side (LGB)"
      ],
      "metadata": {
        "id": "14gY4Ud4DSFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%python\n",
        "from lyk_config import k, conf_th, DEBUG, load_data\n",
        "import sys\n",
        "sys.path.append('../input/timm045/')\n",
        "import timm\n",
        "\n",
        "from itertools import zip_longest\n",
        "import json\n",
        "import math\n",
        "import gc\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import joblib\n",
        "import lightgbm as lgb\n",
        "from scipy.sparse import hstack, vstack, csc_matrix, csr_matrix\n",
        "import editdistance\n",
        "import networkx as nx\n",
        "\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "NUM_CLASSES = 11014\n",
        "NUM_WORKERS = 2\n",
        "SEED = 0\n",
        "\n",
        "###\n",
        "import time\n",
        "from contextlib import contextmanager\n",
        "from collections import defaultdict\n",
        "map_used_time = defaultdict(float)\n",
        "@contextmanager\n",
        "def timer(title):\n",
        "    t0 = time.time()\n",
        "    yield\n",
        "    tt = time.time() - t0\n",
        "    map_used_time[title] += tt\n",
        "    print(\"  {} - done in {:.5f}s\".format(title, tt))\n",
        "\n",
        "\n",
        "df, img_dir = load_data()\n",
        "\n",
        "stop_words = set([\n",
        "    'promo','diskon','baik','terbaik', 'murah',\n",
        "    'termurah', 'harga', 'price', 'best', 'seller',\n",
        "    'bestseller', 'ready', 'stock', 'stok', 'limited',\n",
        "    'bagus', 'kualitas', 'berkualitas', 'hari', 'ini',\n",
        "    'jadi', 'gratis',\n",
        "])\n",
        "\n",
        "titles = [\n",
        "    title.translate(str.maketrans({_: ' ' for _ in string.punctuation}))\n",
        "    for title in df['title'].str.lower().values\n",
        "]\n",
        "\n",
        "tokenizer = TweetTokenizer()\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words,\n",
        "                                   binary=True,\n",
        "                                   min_df=2,\n",
        "                                   token_pattern='(?u)\\\\b\\\\w+\\\\b',\n",
        "                                   tokenizer=tokenizer.tokenize,\n",
        "                                   dtype=np.float32,\n",
        "                                   norm='l2')\n",
        "tfidf_feats = tfidf_vectorizer.fit_transform(titles)\n",
        "\n",
        "with timer('load'):\n",
        "    similarities_bert, indexes_bert = joblib.load('/tmp/lyk_bert_data.pkl')\n",
        "    similarities_img, indexes_img = joblib.load('/tmp/lyk_img_data.pkl')\n",
        "    st_sizes, img_hs, img_ws = joblib.load('/tmp/lyk_img_meta_data.pkl')\n",
        "    similarities_mm, indexes_mm = joblib.load('/tmp/lyk_mm_data.pkl')\n",
        "\n",
        "    row = indexes_bert.ravel()\n",
        "    col = np.arange(len(indexes_bert)).repeat(k)\n",
        "    data = similarities_bert.ravel()\n",
        "    simmat_bert = {(i, j): d for i, j, d in zip(col, row, data)}\n",
        "\n",
        "    row = indexes_img.ravel()\n",
        "    col = np.arange(len(indexes_img)).repeat(k)\n",
        "    data = similarities_img.ravel()\n",
        "    simmat_img = {(i, j): d for i, j, d in zip(col, row, data)}\n",
        "\n",
        "    row = indexes_mm.ravel()\n",
        "    col = np.arange(len(indexes_mm)).repeat(k)\n",
        "    data = similarities_mm.ravel()\n",
        "    simmat_mm = {(i, j): d for i, j, d in zip(col, row, data)}\n",
        "\n",
        "del row, col, data\n",
        "gc.collect()\n",
        "\n",
        "mean_sim_img_top5 = similarities_img[:, :5].mean(1)\n",
        "mean_sim_bert_top5 = similarities_bert[:, :5].mean(1)\n",
        "mean_mean_sim_img_top5 = mean_sim_img_top5[indexes_img[:, :5]].mean(1)\n",
        "mean_mean_sim_bert_top5 = mean_sim_bert_top5[indexes_bert[:, :5]].mean(1)\n",
        "\n",
        "mean_sim_img_top5 = (mean_sim_img_top5 - mean_sim_img_top5.mean()) / mean_sim_img_top5.std()\n",
        "mean_sim_bert_top5 = (mean_sim_bert_top5 - mean_sim_bert_top5.mean()) / mean_sim_bert_top5.std()\n",
        "mean_mean_sim_img_top5 = (mean_mean_sim_img_top5 - mean_mean_sim_img_top5.mean()) / mean_mean_sim_img_top5.std()\n",
        "mean_mean_sim_bert_top5 = (mean_mean_sim_bert_top5 - mean_mean_sim_bert_top5.mean()) / mean_mean_sim_bert_top5.std()\n",
        "\n",
        "mean_sim_img_top15 = similarities_img[:, :15].mean(1)\n",
        "mean_sim_bert_top15 = similarities_bert[:, :15].mean(1)\n",
        "mean_sim_img_top15 = (mean_sim_img_top15 - mean_sim_img_top15.mean()) / mean_sim_img_top15.std()\n",
        "mean_sim_bert_top15 = (mean_sim_bert_top15 - mean_sim_bert_top15.mean()) / mean_sim_bert_top15.std()\n",
        "\n",
        "mean_sim_img_top30 = similarities_img[:, :30].mean(1)\n",
        "mean_sim_bert_top30 = similarities_bert[:, :30].mean(1)\n",
        "mean_sim_img_top30 = (mean_sim_img_top30 - mean_sim_img_top30.mean()) / mean_sim_img_top30.std()\n",
        "mean_sim_bert_top30 = (mean_sim_bert_top30 - mean_sim_bert_top30.mean()) / mean_sim_bert_top30.std()\n",
        "\n",
        "mean_sim_mm_top5 = similarities_mm[:, :5].mean(1)\n",
        "mean_mean_sim_mm_top5 = mean_sim_mm_top5[indexes_mm[:, :5]].mean(1)\n",
        "\n",
        "mean_sim_mm_top5 = (mean_sim_mm_top5 - mean_sim_mm_top5.mean()) / mean_sim_mm_top5.std()\n",
        "mean_mean_sim_mm_top5 = (mean_mean_sim_mm_top5 - mean_mean_sim_mm_top5.mean()) / mean_mean_sim_mm_top5.std()\n",
        "\n",
        "mean_sim_mm_top15 = similarities_mm[:, :15].mean(1)\n",
        "mean_sim_mm_top15 = (mean_sim_mm_top15 - mean_sim_mm_top15.mean()) / mean_sim_mm_top15.std()\n",
        "\n",
        "mean_sim_mm_top30 = similarities_mm[:, :30].mean(1)\n",
        "mean_sim_mm_top30 = (mean_sim_mm_top30 - mean_sim_mm_top30.mean()) / mean_sim_mm_top30.std()\n",
        "\n",
        "row_titles = df['title'].values\n",
        "posting_ids = df['posting_id'].values\n",
        "\n",
        "tmp_dir = Path('/tmp/rows')\n",
        "tmp_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "rows = []\n",
        "for i in tqdm(range(len(df))):\n",
        "    right_indexes = set(indexes_img[i].tolist() + indexes_bert[i].tolist())\n",
        "\n",
        "    for _, j in enumerate(right_indexes):\n",
        "        if i == j:\n",
        "            continue\n",
        "        sim_img = simmat_img.get((i, j), 0)\n",
        "        sim_bert = simmat_bert.get((i, j), 0)\n",
        "        sim_mm = simmat_mm.get((i, j), 0)\n",
        "        if sim_img == 0 and sim_bert == 0:\n",
        "            continue\n",
        "\n",
        "        rows.append({\n",
        "            'i': i,\n",
        "            'j': j,\n",
        "            'posting_id': posting_ids[i],\n",
        "            'posting_id_target': posting_ids[j],\n",
        "            'sim_img': sim_img,\n",
        "            'sim_bert': sim_bert,\n",
        "            'sim_mm': sim_mm,\n",
        "            'edit_distance': editdistance.eval(titles[i], titles[j]),\n",
        "            'title_len': len(row_titles[i]),\n",
        "            'title_len_target': len(row_titles[j]),\n",
        "            'title_num_words': len(row_titles[i].split()),\n",
        "            'title_num_words_target': len(row_titles[j].split()),\n",
        "            'mean_sim_img_top5': mean_sim_img_top5[i],\n",
        "            'mean_sim_img_target_top5': mean_sim_img_top5[j],\n",
        "            'mean_sim_bert_top5': mean_sim_bert_top5[i],\n",
        "            'mean_sim_bert_target_top5': mean_sim_bert_top5[j],\n",
        "            'mean_sim_img_top15': mean_sim_img_top15[i],\n",
        "            'mean_sim_img_target_top15': mean_sim_img_top15[j],\n",
        "            'mean_sim_bert_top15': mean_sim_bert_top15[i],\n",
        "            'mean_sim_bert_target_top15': mean_sim_bert_top15[j],\n",
        "            'mean_sim_img_top30': mean_sim_img_top30[i],\n",
        "            'mean_sim_img_target_top30': mean_sim_img_top30[j],\n",
        "            'mean_sim_bert_top30': mean_sim_bert_top30[i],\n",
        "            'mean_sim_bert_target_top30': mean_sim_bert_top30[j],\n",
        "            'st_size': st_sizes[i],\n",
        "            'st_size_target': st_sizes[j],\n",
        "            'wxh/st_size': img_ws[i] * img_hs[i] / st_sizes[i],\n",
        "            'wxh/st_size_target': img_ws[j] * img_hs[j] / st_sizes[j],\n",
        "            'mean_mean_sim_img_top5': mean_mean_sim_img_top5[i],\n",
        "            'mean_mean_sim_img_target_top5': mean_mean_sim_img_top5[j],\n",
        "            'mean_mean_sim_bert_top5': mean_mean_sim_bert_top5[i],\n",
        "            'mean_mean_sim_bert_target_top5': mean_mean_sim_bert_top5[j],\n",
        "            'mean_sim_mm_top5': mean_sim_mm_top5[i],\n",
        "            'mean_sim_mm_target_top5': mean_sim_mm_top5[j],\n",
        "            'mean_sim_mm_top15': mean_sim_mm_top15[i],\n",
        "            'mean_sim_mm_target_top15': mean_sim_mm_top15[j],\n",
        "            'mean_sim_mm_top30': mean_sim_mm_top30[i],\n",
        "            'mean_sim_mm_target_top30': mean_sim_mm_top30[j],\n",
        "            'mean_mean_sim_mm_top5': mean_mean_sim_mm_top5[i],\n",
        "            'mean_mean_sim_mm_target_top5': mean_mean_sim_mm_top5[j],\n",
        "        })\n",
        "\n",
        "    if i % 10000 == 9999 or i == len(df) - 1:\n",
        "        tmp_df = pd.DataFrame(rows)\n",
        "        for col in tmp_df.columns:\n",
        "            if tmp_df[col].dtype == 'float64':\n",
        "                tmp_df[col] = tmp_df[col].astype('float32')\n",
        "            elif tmp_df[col].dtype == 'int64':\n",
        "                tmp_df[col] = tmp_df[col].astype('int32')\n",
        "        tmp_df.to_feather(tmp_dir / f'{i}.feather')\n",
        "        rows = []\n",
        "\n",
        "df.drop(['image', 'title'], axis=1, inplace=True)\n",
        "del (\n",
        "    mean_sim_img_top5, mean_sim_img_top15, mean_sim_img_top30, mean_mean_sim_img_top5,\n",
        "    mean_sim_bert_top5, mean_sim_bert_top15, mean_sim_bert_top30, mean_mean_sim_bert_top5,\n",
        "    mean_sim_mm_top5, mean_sim_mm_top15, mean_sim_mm_top30, mean_mean_sim_mm_top5,\n",
        "    simmat_img, simmat_bert, simmat_mm,\n",
        "    similarities_img, indexes_img,\n",
        "    similarities_bert, indexes_bert,\n",
        "    similarities_mm, indexes_mm,\n",
        ")\n",
        "gc.collect()\n",
        "with timer('to_frame'):\n",
        "    df_pair = pd.concat([pd.read_feather(path) for path in tmp_dir.glob('**/*.feather')], axis=0).reset_index(drop=True)\n",
        "del rows\n",
        "gc.collect()\n",
        "\n",
        "with timer('sim_tfidf'):\n",
        "    df_pair['sim_tfidf'] = tfidf_feats[df_pair['i'].values].multiply(tfidf_feats[df_pair['j'].values]).sum(axis=1)\n",
        "df_pair['title_len_diff'] = np.abs(df_pair['title_len'] - df_pair['title_len_target'])\n",
        "df_pair['title_num_words_diff'] = np.abs(df_pair['title_num_words'] - df_pair['title_num_words_target'])\n",
        "\n",
        "del tfidf_feats\n",
        "gc.collect()\n",
        "###\n",
        "\n",
        "from cuml import ForestInference\n",
        "import treelite\n",
        "list_clf = []\n",
        "for clf in joblib.load('../input/shopee/boosters_v34_v45_mm.pickle'):\n",
        "    clf.save_model('/tmp/tmp.lgb')\n",
        "    fi = ForestInference()\n",
        "    fi.load_from_treelite_model(treelite.Model.load('/tmp/tmp.lgb', model_format='lightgbm'))\n",
        "    list_clf.append(fi)\n",
        "\n",
        "X = df_pair[[\n",
        "    'sim_img', 'sim_tfidf', 'sim_bert', 'sim_mm', 'edit_distance',\n",
        "    'title_len', 'title_len_target', 'title_len_diff',\n",
        "    'title_num_words', 'title_num_words_target', 'title_num_words_diff',\n",
        "    'mean_sim_img_top5', 'mean_sim_img_target_top5',\n",
        "    'mean_sim_bert_top5', 'mean_sim_bert_target_top5',\n",
        "    'mean_sim_mm_top5', 'mean_sim_mm_target_top5',\n",
        "    'mean_sim_img_top15', 'mean_sim_img_target_top15',\n",
        "    'mean_sim_bert_top15', 'mean_sim_bert_target_top15',\n",
        "    'mean_sim_mm_top15', 'mean_sim_mm_target_top15',\n",
        "    'mean_sim_img_top30', 'mean_sim_img_target_top30',\n",
        "    'mean_sim_bert_top30', 'mean_sim_bert_target_top30',\n",
        "    'mean_sim_mm_top30', 'mean_sim_mm_target_top30',\n",
        "    'st_size', 'st_size_target',\n",
        "    'wxh/st_size', 'wxh/st_size_target',\n",
        "    'mean_mean_sim_img_top5', 'mean_mean_sim_img_target_top5',\n",
        "    'mean_mean_sim_bert_top5', 'mean_mean_sim_bert_target_top5',\n",
        "    'mean_mean_sim_mm_top5', 'mean_mean_sim_mm_target_top5',\n",
        "]]\n",
        "\n",
        "## passing as cupy array might be able to avoid multipy copy to GPU.\n",
        "X = cp.asarray(X[clf.feature_name()].values.astype(np.float32))\n",
        "df_pair = df_pair[['posting_id', 'posting_id_target']]\n",
        "\n",
        "gc.collect()\n",
        "with timer('predict'):\n",
        "    df_pair['pred'] = np.mean([clf.predict(X).get() for clf in list_clf], axis=0) - conf_th\n",
        "\n",
        "df_pair.to_pickle('submission_lyak.pkl')"
      ],
      "metadata": {
        "trusted": true,
        "id": "7Qzxr8cmDSFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TKM side"
      ],
      "metadata": {
        "id": "Sv9vnGG5DSFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install ../input/shopee-libs/imagesize-1.2.0-py2.py3-none-any.whl \\\n",
        "../input/shopee-libs/PyStemmer-2.0.1/dist/PyStemmer-2.0.1.tar"
      ],
      "metadata": {
        "trusted": true,
        "id": "MJi6mnJODSFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!cp ../input/rapids/rapids.0.18.0 /opt/conda/envs/rapids.tar.gz\n",
        "!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n",
        "sys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\n",
        "sys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\n",
        "sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path\n",
        "!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/"
      ],
      "metadata": {
        "trusted": true,
        "id": "e6srb-m8DSFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import ast\n",
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "from multiprocessing import Pool\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import langid\n",
        "import Levenshtein\n",
        "\n",
        "#import albumentations\n",
        "#from albumentations import *\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from warnings import filterwarnings\n",
        "\n",
        "from contextlib import contextmanager\n",
        "from collections import defaultdict\n",
        "map_used_time = defaultdict(float)\n",
        "@contextmanager\n",
        "def timer(title):\n",
        "    t0 = time.time()\n",
        "    yield\n",
        "    tt = time.time() - t0\n",
        "    map_used_time[title] += tt\n",
        "    print(\"  {} - done in {:.5f}s\".format(title, tt))\n",
        "\n",
        "\n",
        "filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "###\n",
        "\n",
        "import imagesize\n",
        "import Stemmer\n",
        "stemmer = Stemmer.Stemmer('indonesian')\n",
        "DEBUG = len(pd.read_csv('../input/shopee-product-matching/test.csv')) == 3\n",
        "\n",
        "\n",
        "if DEBUG:\n",
        "    data_dir = '../input/shopee-product-matching/train_images/'\n",
        "else:\n",
        "    data_dir = '../input/shopee-product-matching/test_images/'\n",
        "\n",
        "###\n",
        "\n",
        "if DEBUG:\n",
        "    if 1:\n",
        "        nrows = 1000\n",
        "        df_test = pd.read_csv('../input/shopee-libs/train_newfold_stmmedid.csv', nrows=nrows)\n",
        "    else:\n",
        "        df_test = pd.read_csv('../input/shopee-libs/train_newfold_stmmedid.csv').append(\n",
        "            pd.read_csv('../input/shopee-libs/train_newfold_stmmedid.csv'), ignore_index=True\n",
        "        )\n",
        "\n",
        "    label_groups = np.sort(df_test['label_group'].unique())\n",
        "    map_label2id = {g: i for i, g in enumerate(label_groups)}\n",
        "    df_test['label'] = df_test['label_group'].map(map_label2id)\n",
        "    df_test['file_path'] = df_test.image.apply(lambda x: os.path.join(data_dir, f'{x}'))\n",
        "else:\n",
        "    df_test = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
        "    df_test['file_path'] = df_test.image.apply(lambda x: os.path.join(data_dir, f'{x}'))\n",
        "\n",
        "    titles = df_test['title'].str.lower().values\n",
        "\n",
        "    with timer('get lang'):\n",
        "        df_test['lang'] = [langid.classify(t)[0] for t in tqdm(titles)]\n",
        "        list_lang = df_test['lang'].values\n",
        "    with timer('lemmatize'):\n",
        "        titles = np.array([t.encode('ascii').decode('unicode-escape').encode('ascii', 'replace').decode('ascii').replace('?', ' ') for t in titles])\n",
        "        titles = [' '.join(stemmer.stemWords(t.split())) if list_lang[i] in {'id', 'ms'} else t for i, t in enumerate(tqdm(titles))]\n",
        "        df_test['title'] = titles\n",
        "\n",
        "with timer('get image size'):\n",
        "    st_sizes, img_hs, img_ws = joblib.load('/tmp/lyk_img_meta_data.pkl')\n",
        "    df_test['width'] = img_ws\n",
        "    df_test['hight'] = img_hs\n",
        "    df_test['st_size'] = st_sizes\n",
        "    df_test['wxh/st_size'] = df_test['width'] * df_test['hight'] / df_test['st_size']\n",
        "\n",
        "df_test.to_pickle('/tmp/df_test_tkm.pkl')\n",
        "###\n",
        "\n",
        "K = min(60, df_test.shape[0])\n",
        "\n",
        "###\n",
        "print('Computing text embeddings...')\n",
        "import cupy as cp\n",
        "import pickle\n",
        "import gc\n",
        "from cuml.feature_extraction.text import TfidfVectorizer\n",
        "import cudf\n",
        "\n",
        "model = TfidfVectorizer(stop_words=None,\n",
        "                        binary=True,\n",
        "                        max_features=100000,\n",
        "                        max_df=0.3,\n",
        "                        min_df=2,\n",
        "                        dtype=np.float32)\n",
        "\n",
        "with timer('tfidf fit'):\n",
        "    titles = pd.read_csv('../input/shopee-libs/train_newfold_stmmedid.csv',\n",
        "                         usecols=['title'])['title'].values.tolist()\n",
        "    test_titles = df_test.title.values.tolist()\n",
        "    titles += test_titles\n",
        "    model.fit(cudf.Series(titles))\n",
        "    text_embeddings = model.transform(cudf.Series(test_titles))\n",
        "    print('text embeddings shape',text_embeddings.shape)\n",
        "\n",
        "with timer('tfidf pred'):\n",
        "    CHUNK = 1024*4\n",
        "    print('Finding similar titles...')\n",
        "    text_D = np.zeros((df_test.shape[0], K), dtype=np.float32)\n",
        "    text_I = np.zeros((df_test.shape[0], K), dtype=np.int32)\n",
        "\n",
        "\n",
        "    CTS = text_embeddings.shape[0]//CHUNK\n",
        "    if  text_embeddings.shape[0]%CHUNK!=0: CTS += 1\n",
        "    cnt = 0\n",
        "    for j in range( CTS ):\n",
        "\n",
        "        a = j*CHUNK\n",
        "        b = (j+1)*CHUNK\n",
        "        b = min(b, text_embeddings.shape[0])\n",
        "        print('chunk',a,'to',b, text_embeddings.shape[0])\n",
        "\n",
        "        #COSINE SIMILARITY DISTANCE\n",
        "        cts = (text_embeddings * text_embeddings[a:b].T).T.toarray()\n",
        "        indices = cp.argsort(cts, axis=1)\n",
        "\n",
        "        for k in range(b-a):\n",
        "            idx = indices[k][::-1]\n",
        "            text_I[cnt] = idx[:K].get()\n",
        "            text_D[cnt] = cts[k, idx[:K]].get()\n",
        "            cnt += 1\n",
        "\n",
        "del text_embeddings, indices, cts\n",
        "gc.collect()\n",
        "###\n",
        "\n",
        "img_D = np.load('/tmp/img_D_qe.npy')\n",
        "img_I = np.load('/tmp/img_I_qe.npy')\n",
        "\n",
        "###\n",
        "\n",
        "bert_D = np.load('/tmp/brt_D_qe.npy')\n",
        "bert_I = np.load('/tmp/brt_I_qe.npy')\n",
        "\n",
        "###\n",
        "\n",
        "bth_D = np.load('/tmp/bth_D_qe.npy')\n",
        "bth_I = np.load('/tmp/bth_I_qe.npy')\n",
        "###\n",
        "\n",
        "mut_D = np.load('/tmp/mut_D_qe.npy')\n",
        "mut_I = np.load('/tmp/mut_I_qe.npy')\n",
        "###\n",
        "\n",
        "map_col2id = {}\n",
        "###\n",
        "\n",
        "import langid\n",
        "import Levenshtein\n",
        "titles = df_test['title'].values\n",
        "titles_set = [set(t) for t in titles]\n",
        "langs = df_test['lang'].values\n",
        "st_size = df_test['st_size'].values\n",
        "wh_st_size = df_test['wxh/st_size'].values\n",
        "###\n",
        "\n",
        "numset = set('0123456789')\n",
        "\n",
        "###\n",
        "text_D = np.array(text_D)\n",
        "txt_cnt_all = np.vstack([(text_D > t).sum(axis=1) for t in [0.9, 0.8, 0.7, 0.6, 0.5]]).T\n",
        "txt_avg_raw_all = text_D.mean(axis=1)\n",
        "txt_avg_all = (txt_avg_raw_all - txt_avg_raw_all.mean()) / txt_avg_raw_all.std()\n",
        "txt_std_all = text_D.std(axis=1)\n",
        "\n",
        "txt_avg_5_all = text_D[:, :5].mean(axis=1)\n",
        "txt_avg_10_all = text_D[:, :10].mean(axis=1)\n",
        "txt_avg_15_all = text_D[:, :15].mean(axis=1)\n",
        "txt_avg_30_all = text_D[:, :30].mean(axis=1)\n",
        "\n",
        "txt_avg_5_all = (txt_avg_5_all - txt_avg_5_all.mean()) / txt_avg_5_all.std()\n",
        "txt_avg_10_all = (txt_avg_10_all - txt_avg_10_all.mean()) / txt_avg_10_all.std()\n",
        "txt_avg_15_all = (txt_avg_15_all - txt_avg_15_all.mean()) / txt_avg_15_all.std()\n",
        "txt_avg_30_all = (txt_avg_30_all - txt_avg_30_all.mean()) / txt_avg_30_all.std()\n",
        "\n",
        "###\n",
        "brt_cnt_all = np.vstack([(bert_D > t).sum(axis=1) for t in [0.9, 0.8, 0.7, 0.6, 0.5]]).T\n",
        "brt_avg_raw_all = bert_D.mean(axis=1)\n",
        "brt_avg_all = (brt_avg_raw_all - brt_avg_raw_all.mean()) / brt_avg_raw_all.std()\n",
        "brt_std_all = bert_D.std(axis=1)\n",
        "\n",
        "brt_avg_5_all = bert_D[:, :5].mean(axis=1)\n",
        "brt_avg_10_all = bert_D[:, :10].mean(axis=1)\n",
        "brt_avg_15_all = bert_D[:, :15].mean(axis=1)\n",
        "brt_avg_30_all = bert_D[:, :30].mean(axis=1)\n",
        "\n",
        "brt_avg_5_all = (brt_avg_5_all - brt_avg_5_all.mean()) / brt_avg_5_all.std()\n",
        "brt_avg_10_all = (brt_avg_10_all - brt_avg_10_all.mean()) / brt_avg_10_all.std()\n",
        "brt_avg_15_all = (brt_avg_15_all - brt_avg_15_all.mean()) / brt_avg_15_all.std()\n",
        "brt_avg_30_all = (brt_avg_30_all - brt_avg_30_all.mean()) / brt_avg_30_all.std()\n",
        "\n",
        "###\n",
        "bth_cnt_all = np.vstack([(bth_D > t).sum(axis=1) for t in [0.9, 0.8, 0.7, 0.6, 0.5]]).T\n",
        "bth_avg_raw_all = bth_D.mean(axis=1)\n",
        "bth_avg_all = (bth_avg_raw_all - bth_avg_raw_all.mean()) / bth_avg_raw_all.std()\n",
        "bth_std_all = bth_D.std(axis=1)\n",
        "\n",
        "bth_avg_5_all = bth_D[:, :5].mean(axis=1)\n",
        "bth_avg_10_all = bth_D[:, :10].mean(axis=1)\n",
        "bth_avg_15_all = bth_D[:, :15].mean(axis=1)\n",
        "bth_avg_30_all = bth_D[:, :30].mean(axis=1)\n",
        "\n",
        "bth_avg_5_all = (bth_avg_5_all - bth_avg_5_all.mean()) / bth_avg_5_all.std()\n",
        "bth_avg_10_all = (bth_avg_10_all - bth_avg_10_all.mean()) / bth_avg_10_all.std()\n",
        "bth_avg_15_all = (bth_avg_15_all - bth_avg_15_all.mean()) / bth_avg_15_all.std()\n",
        "bth_avg_30_all = (bth_avg_30_all - bth_avg_30_all.mean()) / bth_avg_30_all.std()\n",
        "\n",
        "###\n",
        "mut_cnt_all = np.vstack([(mut_D > t).sum(axis=1) for t in [0.9, 0.8, 0.7, 0.6, 0.5]]).T\n",
        "mut_avg_raw_all = mut_D.mean(axis=1)\n",
        "mut_avg_all = (mut_avg_raw_all - mut_avg_raw_all.mean()) / mut_avg_raw_all.std()\n",
        "mut_std_all = mut_D.std(axis=1)\n",
        "\n",
        "mut_avg_5_all = mut_D[:, :5].mean(axis=1)\n",
        "mut_avg_10_all = mut_D[:, :10].mean(axis=1)\n",
        "mut_avg_15_all = mut_D[:, :15].mean(axis=1)\n",
        "mut_avg_30_all = mut_D[:, :30].mean(axis=1)\n",
        "\n",
        "mut_avg_5_all = (mut_avg_5_all - mut_avg_5_all.mean()) / mut_avg_5_all.std()\n",
        "mut_avg_10_all = (mut_avg_10_all - mut_avg_10_all.mean()) / mut_avg_10_all.std()\n",
        "mut_avg_15_all = (mut_avg_15_all - mut_avg_15_all.mean()) / mut_avg_15_all.std()\n",
        "mut_avg_30_all = (mut_avg_30_all - mut_avg_30_all.mean()) / mut_avg_30_all.std()\n",
        "\n",
        "###\n",
        "img_cnt_all = np.vstack([(img_D > t).sum(axis=1) for t in [0.9, 0.8, 0.7, 0.6, 0.5]]).T\n",
        "img_avg_raw_all = img_D.mean(axis=1)\n",
        "img_avg_all = (img_avg_raw_all - img_avg_raw_all.mean()) / img_avg_raw_all.std()\n",
        "img_std_all = img_D.std(axis=1)\n",
        "\n",
        "img_avg_5_all = img_D[:, :5].mean(axis=1)\n",
        "img_avg_10_all = img_D[:, :10].mean(axis=1)\n",
        "img_avg_15_all = img_D[:, :15].mean(axis=1)\n",
        "img_avg_30_all = img_D[:, :30].mean(axis=1)\n",
        "\n",
        "img_avg_5_all = (img_avg_5_all - img_avg_5_all.mean()) / img_avg_5_all.std()\n",
        "img_avg_10_all = (img_avg_10_all - img_avg_10_all.mean()) / img_avg_10_all.std()\n",
        "img_avg_15_all = (img_avg_15_all - img_avg_15_all.mean()) / img_avg_15_all.std()\n",
        "img_avg_30_all = (img_avg_30_all - img_avg_30_all.mean()) / img_avg_30_all.std()\n",
        "\n",
        "width_hight = df_test[['width', 'hight']].values\n",
        "\n",
        "list_pred_id = [[] for _ in range(df_test.shape[0])]\n",
        "\n",
        "indices = df_test.index.values\n",
        "\n",
        "ptr = 0\n",
        "all_feat = np.memmap('/tmp/tkm_feat.dat', dtype='float32', mode='w+', shape=(df_test.shape[0] * 60 * 5, 150), order='F')\n",
        "\n",
        "feat = np.zeros((60 * 5, 150), dtype='float32')\n",
        "\n",
        "list_idx = []\n",
        "list_idx2 = []\n",
        "list_feats = []\n",
        "for i in tqdm(indices):\n",
        "    img_d = img_D[i]\n",
        "    img_i = img_I[i]\n",
        "\n",
        "    img_cnt = img_cnt_all[i]\n",
        "    img_avg = img_avg_all[i]\n",
        "    img_std = img_std_all[i]\n",
        "\n",
        "    img_width ,img_hight = width_hight[i]\n",
        "\n",
        "    ###\n",
        "    txt_d = text_D[i]\n",
        "    txt_i = text_I[i]\n",
        "\n",
        "    txt_cnt = txt_cnt_all[i]\n",
        "    txt_avg = txt_avg_all[i]\n",
        "    txt_std = txt_std_all[i]\n",
        "\n",
        "    txt_set = set(titles[i])\n",
        "    ###\n",
        "    brt_d = bert_D[i]\n",
        "    brt_i = bert_I[i]\n",
        "\n",
        "    brt_cnt = brt_cnt_all[i]\n",
        "    brt_avg = brt_avg_all[i]\n",
        "    brt_std = brt_std_all[i]\n",
        "\n",
        "    brt_set = set(titles[i])\n",
        "    bth_d = bth_D[i]\n",
        "    bth_i = bth_I[i]\n",
        "\n",
        "    bth_cnt = bth_cnt_all[i]\n",
        "    bth_avg = bth_avg_all[i]\n",
        "    bth_std = bth_std_all[i]\n",
        "\n",
        "    bth_set = set(titles[i])\n",
        "    mut_d = mut_D[i]\n",
        "    mut_i = mut_I[i]\n",
        "\n",
        "    mut_cnt = mut_cnt_all[i]\n",
        "    mut_avg = mut_avg_all[i]\n",
        "    mut_std = mut_std_all[i]\n",
        "\n",
        "    mut_set = set(titles[i])\n",
        "\n",
        "    map_feat = {}\n",
        "    for j in range(K):\n",
        "        _w, _h = width_hight[img_i[j]]\n",
        "        _img_cnt = img_cnt_all[img_i[j]]\n",
        "        _img_avg = img_avg_all[img_i[j]]\n",
        "        _img_std = img_std_all[img_i[j]]\n",
        "\n",
        "        diff_width = abs(img_width - _w)\n",
        "        diff_hight = abs(img_hight - _h)\n",
        "        d = {\n",
        "            'img_sim': img_d[j],\n",
        "            'img_avg': img_avg,\n",
        "            'img_std': img_std,\n",
        "            'img_avg2': _img_avg,\n",
        "            'img_std2': _img_std,\n",
        "\n",
        "            'img_avg_raw': img_avg_raw_all[i],\n",
        "            'img_avg2_raw': img_avg_raw_all[img_i[j]],\n",
        "\n",
        "            'diff_width': diff_width,\n",
        "            'diff_hight': diff_hight,\n",
        "            'img_width': img_width,\n",
        "            'img_hight': img_hight,\n",
        "            'img_width2': _w,\n",
        "            'img_hight2': _h,\n",
        "\n",
        "            'st_size': st_size[i],\n",
        "            'st_size2': st_size[img_i[j]],\n",
        "            'wh_st_size': wh_st_size[i],\n",
        "            'wh_st_size2': wh_st_size[img_i[j]]\n",
        "        }\n",
        "        d.update({f'img_cnt_{ii}': img_cnt[ii] for ii in range(img_cnt.shape[0])})\n",
        "        d.update({f'img_cnt2_{ii}': _img_cnt[ii] for ii in range(_img_cnt.shape[0])})\n",
        "        map_feat[img_i[j]] = d\n",
        "\n",
        "    for j in range(K):\n",
        "        _txt_set = titles_set[txt_i[j]]\n",
        "        _txt_cnt = txt_cnt_all[txt_i[j]]\n",
        "        _txt_avg = txt_avg_all[txt_i[j]]\n",
        "        _txt_std = txt_std_all[txt_i[j]]\n",
        "        diff_txt_set = set(titles[txt_i[j]]) & txt_set\n",
        "        diff_txt_set = len(numset & diff_txt_set) / (len(diff_txt_set) + 1)\n",
        "        xor_txt_set = set(titles[txt_i[j]]) ^ txt_set\n",
        "        xor_txt_set = len(numset & xor_txt_set) / (len(xor_txt_set) + 1)\n",
        "        jac_txt = len(txt_set & _txt_set) / (len(txt_set | _txt_set) + 1)\n",
        "        lev_dist = Levenshtein.distance(titles[i], titles[txt_i[j]])\n",
        "        d = {\n",
        "            'txt_sim': txt_d[j],\n",
        "            'txt_avg': txt_avg,\n",
        "            'txt_std': txt_std,\n",
        "            'txt_avg2': _txt_avg,\n",
        "            'txt_std2': _txt_std,\n",
        "\n",
        "            'txt_avg_raw': txt_avg_raw_all[i],\n",
        "            'txt_avg2_raw': txt_avg_raw_all[txt_i[j]],\n",
        "\n",
        "            'jac_txt': jac_txt,\n",
        "            'diff_txt_set': diff_txt_set,\n",
        "            'xor_txt_set': xor_txt_set,\n",
        "            'lev_dist': lev_dist,\n",
        "            'len_txt': len(titles[i]),\n",
        "            'len_txt2': len(titles[txt_i[j]]),\n",
        "            'lang_en': int(langs[i] == 'en'),\n",
        "            'lang_en2': int(langs[txt_i[j]] == 'en'),\n",
        "        }\n",
        "        d.update({f'txt_cnt_{ii}': txt_cnt[ii] for ii in range(txt_cnt.shape[0])})\n",
        "        d.update({f'txt_cnt2_{ii}': _txt_cnt[ii] for ii in range(_txt_cnt.shape[0])})\n",
        "        if txt_i[j] in map_feat:\n",
        "            map_feat[txt_i[j]].update(d)\n",
        "        else:\n",
        "            map_feat[txt_i[j]] = d\n",
        "\n",
        "    for j in range(K):\n",
        "        _bth_cnt = bth_cnt_all[bth_i[j]]\n",
        "        _bth_avg = bth_avg_all[bth_i[j]]\n",
        "        _bth_std = bth_std_all[bth_i[j]]\n",
        "        if bth_i[j] in map_feat:\n",
        "            d = map_feat[bth_i[j]]\n",
        "        else:\n",
        "            d = {}\n",
        "        d.update({\n",
        "            'bth_sim': bth_d[j],\n",
        "            'bth_avg': bth_avg,\n",
        "            'bth_std': bth_std,\n",
        "            'bth_avg2': _bth_avg,\n",
        "            'bth_std2': _bth_std,\n",
        "\n",
        "            'bth_avg_raw': bth_avg_raw_all[i],\n",
        "            'bth_avg2_raw': bth_avg_raw_all[bth_i[j]],\n",
        "        })\n",
        "        d.update({f'bth_cnt_{ii}': bth_cnt[ii] for ii in range(bth_cnt.shape[0])})\n",
        "        d.update({f'bth_cnt2_{ii}': _bth_cnt[ii] for ii in range(_bth_cnt.shape[0])})\n",
        "        if 'lev_dist' not in d:\n",
        "            _bth_set = titles_set[bth_i[j]] #set(titles[bth_i[j]])\n",
        "            diff_bth_set = set(titles[bth_i[j]]) & bth_set\n",
        "            diff_bth_set = len(numset & diff_bth_set) / (len(diff_bth_set) + 1)\n",
        "            xor_bth_set = set(titles[bth_i[j]]) ^ bth_set\n",
        "            xor_bth_set = len(numset & xor_bth_set) / (len(xor_bth_set) + 1)\n",
        "            jac_bth = len(bth_set & _bth_set) / (len(bth_set | _bth_set) + 1)\n",
        "            lev_dist = Levenshtein.distance(titles[i], titles[bth_i[j]])\n",
        "            d.update({\n",
        "                'jac_txt': jac_bth,\n",
        "                'diff_txt_set': diff_bth_set,\n",
        "                'xor_txt_set': xor_bth_set,\n",
        "                'lev_dist': lev_dist,\n",
        "                'len_txt': len(titles[i]),\n",
        "                'len_txt2': len(titles[bth_i[j]]),\n",
        "                'lang_en': int(langs[i] == 'en'),\n",
        "                'lang_en2': int(langs[bth_i[j]] == 'en'),\n",
        "            })\n",
        "        if 'img_width' not in d:\n",
        "            _w, _h = width_hight[bth_i[j]]\n",
        "            diff_width = abs(img_width - _w)\n",
        "            diff_hight = abs(img_hight - _h)\n",
        "            d.update({\n",
        "                'diff_width': diff_width,\n",
        "                'diff_hight': diff_hight,\n",
        "                 'img_width': img_width,\n",
        "                 'img_hight': img_hight,\n",
        "                 'img_width2': _w,\n",
        "                 'img_hight2': _h,\n",
        "\n",
        "                     'st_size': st_size[i],\n",
        "                     'st_size2': st_size[bth_i[j]],\n",
        "                     'wh_st_size': wh_st_size[i],\n",
        "                     'wh_st_size2': wh_st_size[bth_i[j]]\n",
        "                     })\n",
        "        map_feat[bth_i[j]] = d\n",
        "\n",
        "    for j in range(K):\n",
        "        _mut_cnt = mut_cnt_all[mut_i[j]]\n",
        "        _mut_avg = mut_avg_all[mut_i[j]]\n",
        "        _mut_std = mut_std_all[mut_i[j]]\n",
        "        if mut_i[j] in map_feat:\n",
        "            d = map_feat[mut_i[j]]\n",
        "        else:\n",
        "            d = {}\n",
        "        d.update({\n",
        "            'mut_sim': mut_d[j],\n",
        "            'mut_avg': mut_avg,\n",
        "            'mut_std': mut_std,\n",
        "            'mut_avg2': _mut_avg,\n",
        "            'mut_std2': _mut_std,\n",
        "            'mut_avg_raw': mut_avg_raw_all[i],\n",
        "            'mut_avg2_raw': mut_avg_raw_all[mut_i[j]],\n",
        "        })\n",
        "        d.update({f'mut_cnt_{ii}': mut_cnt[ii] for ii in range(mut_cnt.shape[0])})\n",
        "        d.update({f'mut_cnt2_{ii}': _mut_cnt[ii] for ii in range(_mut_cnt.shape[0])})\n",
        "        if 'lev_dist' not in d:\n",
        "            _mut_set = titles_set[mut_i[j]]#set(titles[mut_i[j]])\n",
        "            diff_mut_set = set(titles[mut_i[j]]) & mut_set\n",
        "            diff_mut_set = len(numset & diff_mut_set) / (len(diff_mut_set) + 1)\n",
        "            xor_mut_set = set(titles[mut_i[j]]) ^ mut_set\n",
        "            xor_mut_set = len(numset & xor_mut_set) / (len(xor_mut_set) + 1)\n",
        "            jac_mut = len(mut_set & _mut_set) / (len(mut_set | _mut_set) + 1)\n",
        "            lev_dist = Levenshtein.distance(titles[i], titles[mut_i[j]])\n",
        "            d.update({\n",
        "                'jac_txt': jac_mut,\n",
        "                'diff_txt_set': diff_mut_set,\n",
        "                'xor_txt_set': xor_mut_set,\n",
        "                'lev_dist': lev_dist,\n",
        "                'len_txt': len(titles[i]),\n",
        "                'len_txt2': len(titles[mut_i[j]]),\n",
        "                'lang_en': int(langs[i] == 'en'),\n",
        "                'lang_en2': int(langs[mut_i[j]] == 'en'),\n",
        "            })\n",
        "        if 'img_width' not in d:\n",
        "            _w, _h = width_hight[mut_i[j]]\n",
        "            diff_width = abs(img_width - _w)\n",
        "            diff_hight = abs(img_hight - _h)\n",
        "            d.update({\n",
        "                'diff_width': diff_width,\n",
        "                'diff_hight': diff_hight,\n",
        "                'img_width': img_width,\n",
        "                'img_hight': img_hight,\n",
        "                'img_width2': _w,\n",
        "                'img_hight2': _h,\n",
        "                'st_size': st_size[i],\n",
        "                'st_size2': st_size[mut_i[j]],\n",
        "                'wh_st_size': wh_st_size[i],\n",
        "                'wh_st_size2': wh_st_size[mut_i[j]]\n",
        "            })\n",
        "        map_feat[mut_i[j]] = d\n",
        "\n",
        "    for j in range(K):\n",
        "        _brt_cnt = brt_cnt_all[brt_i[j]]\n",
        "        _brt_avg = brt_avg_all[brt_i[j]]\n",
        "        _brt_std = brt_std_all[brt_i[j]]\n",
        "        if brt_i[j] in map_feat:\n",
        "            d = map_feat[brt_i[j]]\n",
        "        else:\n",
        "            d = {}\n",
        "        d.update({\n",
        "            'brt_sim': brt_d[j],\n",
        "            'brt_avg': brt_avg,\n",
        "            'brt_std': brt_std,\n",
        "            'brt_avg2': _brt_avg,\n",
        "            'brt_std2': _brt_std,\n",
        "            'brt_avg_raw': brt_avg_raw_all[i],\n",
        "            'brt_avg2_raw': brt_avg_raw_all[brt_i[j]],\n",
        "        })\n",
        "        d.update({f'brt_cnt_{ii}': brt_cnt[ii] for ii in range(brt_cnt.shape[0])})\n",
        "        d.update({f'brt_cnt2_{ii}': _brt_cnt[ii] for ii in range(_brt_cnt.shape[0])})\n",
        "        if 'lev_dist' not in d:\n",
        "            _brt_set = titles_set[brt_i[j]]\n",
        "            diff_brt_set = set(titles[brt_i[j]]) & brt_set\n",
        "            diff_brt_set = len(numset & diff_brt_set) / (len(diff_brt_set) + 1)\n",
        "            xor_brt_set = set(titles[brt_i[j]]) ^ brt_set\n",
        "            xor_brt_set = len(numset & xor_brt_set) / (len(xor_brt_set) + 1)\n",
        "            jac_brt = len(brt_set & _brt_set) / (len(brt_set | _brt_set) + 1)\n",
        "            lev_dist = Levenshtein.distance(titles[i], titles[brt_i[j]])\n",
        "            d.update({\n",
        "                'jac_txt': jac_brt,\n",
        "                'diff_txt_set': diff_brt_set,\n",
        "                'xor_txt_set': xor_brt_set,\n",
        "                'lev_dist': lev_dist,\n",
        "                'len_txt': len(titles[i]),\n",
        "                'len_txt2': len(titles[brt_i[j]]),\n",
        "                'lang_en': int(langs[i] == 'en'),\n",
        "                'lang_en2': int(langs[brt_i[j]] == 'en'),\n",
        "            })\n",
        "        map_feat[brt_i[j]] = d\n",
        "\n",
        "    feat[:] = 0\n",
        "    for ii, (k, map_val) in enumerate(map_feat.items()):\n",
        "        list_idx.append(i)\n",
        "        list_idx2.append(k)\n",
        "        for c, v in map_val.items():\n",
        "            if c not in map_col2id:\n",
        "                map_col2id[c] = len(map_col2id)\n",
        "            feat[ii, map_col2id[c]] = v\n",
        "\n",
        "    all_feat[ptr:ptr + len(map_feat)] = feat[:len(map_feat)]\n",
        "    ptr += len(map_feat)\n",
        "\n",
        "del img_D, img_I, text_D, text_I, bert_D, bert_I, bth_D, bth_I, mut_D, mut_I\n",
        "gc.collect()\n",
        "\n",
        "del list_feats\n",
        "gc.collect()\n",
        "\n",
        "map_weights = {sim: all_feat[:ptr, map_col2id[f'{sim}_sim']] for sim in ['img', 'bth', 'mut', 'txt', 'brt']}\n",
        "\n",
        "del feat\n",
        "gc.collect()\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "list_idx = np.array(list_idx)\n",
        "list_idx2 = np.array(list_idx2)\n",
        "\n",
        "from igraph import Graph\n",
        "map_sim = {}\n",
        "for sim in tqdm(['img', 'bth', 'mut', 'txt', 'brt'], desc='graph'):\n",
        "    weights = map_weights[sim]\n",
        "    idx = weights > 0\n",
        "    with timer('add edges'):\n",
        "        g = Graph()\n",
        "        g.add_vertices(len(df_test))\n",
        "        g.add_edges(list(zip(list_idx[idx], list_idx2[idx])), {'weight': weights[idx]})\n",
        "    with timer('pagerank'):\n",
        "        map_pr = np.array(g.pagerank(damping=0.85, weights='weight', niter=100, eps=1e-06, directed=False))\n",
        "    with timer('pagerank get'):\n",
        "        data1 = map_pr[list_idx]\n",
        "        data2 = map_pr[list_idx2]\n",
        "        data1[weights <= 0] = 0\n",
        "        data2[weights <= 0] = 0\n",
        "        map_sim[f'{sim}_pagerank'] = data1\n",
        "        map_sim[f'{sim}_pagerank2'] = data2\n",
        "    del map_pr, g\n",
        "    gc.collect()\n",
        "\n",
        "for c, v in tqdm(map_sim.items()):\n",
        "    map_col2id[c] = len(map_col2id)\n",
        "    all_feat[:ptr, map_col2id[c]] = v\n",
        "\n",
        "import treelite_runtime\n",
        "from cuml import ForestInference\n",
        "import treelite\n",
        "import pickle\n",
        "import lightgbm as lgb\n",
        "\n",
        "all_weights = {\n",
        "    '../input/shopee-metric-resnet50d512-0328-newfold/0508_qe_best_0.345/': 1,\n",
        "}\n",
        "\n",
        "s = sum(all_weights.values())\n",
        "all_weights = {k: v / s for k, v in all_weights.items()}\n",
        "\n",
        "list_clf = []\n",
        "weights = []\n",
        "thresholds = [] #[0.358, 0.361, 0.350, 0.336, 0.348, 0.346]\n",
        "for path in [\n",
        "    '../input/shopee-metric-resnet50d512-0328-newfold/0508_qe_best_0.345/',\n",
        "    ]:\n",
        "    name = os.path.dirname(path).split('/')[-1]\n",
        "    th = float(name.split('_')[-1])\n",
        "    if all_weights.get(path, 0) == 0:\n",
        "        continue\n",
        "\n",
        "    fi = ForestInference()\n",
        "    fi.load_from_treelite_model(treelite.Model.load(f'{path}/all_data_clf_norm.lgb', model_format='lightgbm'))\n",
        "    list_clf += [fi]\n",
        "    thresholds += [th]\n",
        "    weights += [all_weights[path]]\n",
        "\n",
        "print(weights)\n",
        "print(thresholds)\n",
        "\n",
        "col = lgb.Booster(model_file=f'{path}/all_data_clf_norm.lgb').feature_name()\n",
        "\n",
        "for sf in ['img', 'txt', 'mut', 'bth', 'brt']:\n",
        "    all_feat[:ptr, map_col2id[f'{sf}_avg']] = all_feat[:ptr, map_col2id[f'{sf}_avg_raw']]\n",
        "    all_feat[:ptr, map_col2id[f'{sf}_avg2']] = all_feat[:ptr, map_col2id[f'{sf}_avg2_raw']]\n",
        "\n",
        "CHUNK = 1000000\n",
        "preds = []\n",
        "col_idx = [map_col2id[c] for c in col]\n",
        "\n",
        "for ch in tqdm(range(0, ptr, CHUNK), desc='pred chunk'):\n",
        "    feat = cp.asarray(all_feat[ch:ch+CHUNK, col_idx]).astype('float32')\n",
        "    probs = np.vstack([(c.predict(feat).get() - thresholds[ii]) * weights[ii] for ii, c in enumerate(list_clf)])\n",
        "    preds += probs.sum(axis=0).tolist()\n",
        "    del feat\n",
        "    gc.collect()\n",
        "\n",
        "df_pred = pd.DataFrame(\n",
        "    dict(\n",
        "        posting_id=list_idx,\n",
        "        posting_id_target=list_idx2,\n",
        "        pred=preds[:ptr]\n",
        "    )\n",
        ")\n",
        "\n",
        "idx = df_test.posting_id.values\n",
        "df_pred['posting_id'] = [idx[i] for i in df_pred['posting_id'].values]\n",
        "df_pred['posting_id_target'] = [idx[i] for i in df_pred['posting_id_target'].values]\n",
        "\n",
        "df_pred.to_pickle('submission_tkm.pkl')"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "id": "kdYgLQXMDSFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Postprocess"
      ],
      "metadata": {
        "id": "lU7Xcpk2DSFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_lyk = pd.read_pickle('submission_lyak.pkl')\n",
        "df_lyk_gcn = pd.read_pickle('submission_lyak_gcn.pkl')\n",
        "df_tkm = pd.read_pickle('submission_tkm.pkl')\n",
        "\n",
        "df_lyk['pred'] *= 1\n",
        "df_lyk_gcn['pred'] *= 3\n",
        "df_tkm['pred'] *= 2"
      ],
      "metadata": {
        "trusted": true,
        "id": "oVnGuWNhDSFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = pd.concat([df_lyk, df_lyk_gcn, df_tkm], axis=0, ignore_index=True).groupby(['posting_id', 'posting_id_target'])[['pred']].sum() / 6\n",
        "\n",
        "df_pred.reset_index(inplace=True)\n",
        "df_pred.loc[df_pred['posting_id'] == df_pred['posting_id_target'], 'pred'] = 0.5\n",
        "df_pred.set_index(['posting_id', 'posting_id_target'], inplace=True)\n",
        "\n",
        "df_pred = df_pred.query('pred > 0')\n",
        "df_pred = df_pred[df_pred.apply(lambda row: (row.name[1], row.name[0]) in df_pred.index, axis=1)].reset_index()\n",
        "\n",
        "df_pred"
      ],
      "metadata": {
        "trusted": true,
        "id": "6yrox8j7DSFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from tqdm import tqdm\n",
        "from cugraph.centrality.betweenness_centrality import edge_betweenness_centrality\n",
        "\n",
        "G = nx.Graph()\n",
        "for i, j, w in df_pred[['posting_id', 'posting_id_target', 'pred']].values:\n",
        "    G.add_edge(i, j, weight=w)\n",
        "\n",
        "list_remove_edges = []\n",
        "list_add_edges = []\n",
        "def split_graph(G):\n",
        "    list_comp = list(nx.connected_components(G))\n",
        "    n = len(G.nodes)\n",
        "    if len(list_comp) == 1:\n",
        "        map_bet = edge_betweenness_centrality(G, normalized=True)\n",
        "        map_bet = {(i, j): w  for (i, j), w in map_bet.items()\n",
        "                   if G[i][j]['weight'] < 0.15780210284453428}\n",
        "        if len(map_bet) == 0:\n",
        "            return\n",
        "        edge, val = max(map_bet.items(), key=lambda x: x[1])\n",
        "        if val > 0.11766651703447985:\n",
        "            G.remove_edge(*edge)\n",
        "            list_remove_edges.append(edge)\n",
        "            return split_graph(G)\n",
        "    else:\n",
        "        iters = list_comp\n",
        "        for comp in iters:\n",
        "            if len(comp) > 6:\n",
        "                split_graph(nx.Graph(G.subgraph(comp)))\n",
        "\n",
        "split_graph(G)\n",
        "for edge in list_remove_edges:\n",
        "    G.remove_edge(*edge)\n",
        "\n",
        "def get_score(i, j):\n",
        "    try:\n",
        "        return G[i][j]['weight']\n",
        "    except KeyError:\n",
        "        return -1\n",
        "\n",
        "posting_ids = df_pred['posting_id'].unique()\n",
        "matches = []\n",
        "\n",
        "for i in posting_ids:\n",
        "    if i in G:\n",
        "        m = list(set([i] + list(G.neighbors(i))))\n",
        "    else:\n",
        "        m = [i]\n",
        "    if len(m) > 51:\n",
        "        m = sorted(m, key=lambda x: get_score(i, x), reverse=True)[:51]\n",
        "    matches.append(' '.join(m))\n",
        "matched = pd.DataFrame(dict(posting_id=posting_ids, matches=matches))\n",
        "\n",
        "matched.to_csv('submission.csv', index=False)\n",
        "matched"
      ],
      "metadata": {
        "trusted": true,
        "id": "0xDJX4_lDSFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aghoxx1ADSFE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}